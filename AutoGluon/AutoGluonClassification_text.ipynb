{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb6b0f25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "# same random values for experiments\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "124ceaea",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['label', 'text'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from autogluon.core.utils.loaders import load_pd\n",
    "import pandas as pd\n",
    "\n",
    "#load data\n",
    "train_data = load_pd.load('C:/Users/dzyyu/AutoMLTools/AutoML-Tools/AutoGluon/Datasets/software_requirements_train.txt',  delimiter=':')\n",
    "test_data = load_pd.load('C:/Users/dzyyu/AutoMLTools/AutoML-Tools/AutoGluon/Datasets/software_requirements_test.txt', delimiter=':')\n",
    "\n",
    "subsample_size = 1000  # subsample data for faster demo, try setting this to larger values\n",
    "train_data = train_data.sample(n=subsample_size, random_state=0, replace =True)\n",
    "train_data.head(10)\n",
    "print(train_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc20d04d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AutoGluon infers your prediction problem is: 'multiclass' (because dtype of label-column == object).\n",
      "\tFirst 10 (of 12) unique label values:  ['F', 'US', 'O', 'SC', 'LF', 'L', 'PE', 'SE', 'A', 'MN']\n",
      "\tIf 'multiclass' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Global seed set to 0\n",
      "AutoMM starts to create your model. âœ¨\n",
      "\n",
      "- AutoGluon version is 0.8.2.\n",
      "\n",
      "- Pytorch version is 1.12.1+cpu.\n",
      "\n",
      "- Model will be saved to \"C:\\Users\\dzyyu\\AutoMLTools\\AutoML-Tools\\AutoGluon\\tmp\\8dde5c207412490db4577dc282f2574d-automm_sst\".\n",
      "\n",
      "- Validation metric is \"acc\".\n",
      "\n",
      "- To track the learning progress, you can open a terminal and launch Tensorboard:\n",
      "    ```shell\n",
      "    # Assume you have installed tensorboard\n",
      "    tensorboard --logdir C:\\Users\\dzyyu\\AutoMLTools\\AutoML-Tools\\AutoGluon\\tmp\\8dde5c207412490db4577dc282f2574d-automm_sst\n",
      "    ```\n",
      "\n",
      "Enjoy your coffee, and let AutoMM do the job â˜•â˜•â˜• Learn more at https://auto.gluon.ai\n",
      "\n",
      "0 GPUs are detected, and 0 GPUs will be used.\n",
      "\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name              | Type                         | Params\n",
      "-------------------------------------------------------------------\n",
      "0 | model             | HFAutoModelForTextPrediction | 108 M \n",
      "1 | validation_metric | MulticlassAccuracy           | 0     \n",
      "2 | loss_func         | CrossEntropyLoss             | 0     \n",
      "-------------------------------------------------------------------\n",
      "108 M     Trainable params\n",
      "0         Non-trainable params\n",
      "108 M     Total params\n",
      "435.604   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37cd3eca981d464cb486816ec7ca144c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 3: 'val_acc' reached 0.45000 (best 0.45000), saving model to 'C:\\\\Users\\\\dzyyu\\\\AutoMLTools\\\\AutoML-Tools\\\\AutoGluon\\\\tmp\\\\8dde5c207412490db4577dc282f2574d-automm_sst\\\\epoch=0-step=3.ckpt' as top 3\n",
      "Time limit reached. Elapsed time is 0:03:03. Signaling Trainer to stop.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AutoMM has created your model ğŸ‰ğŸ‰ğŸ‰\n",
      "\n",
      "- To load the model, use the code below:\n",
      "    ```python\n",
      "    from autogluon.multimodal import MultiModalPredictor\n",
      "    predictor = MultiModalPredictor.load(\"C:\\Users\\dzyyu\\AutoMLTools\\AutoML-Tools\\AutoGluon\\tmp\\8dde5c207412490db4577dc282f2574d-automm_sst\")\n",
      "    ```\n",
      "\n",
      "- You can open a terminal and launch Tensorboard to visualize the training log:\n",
      "    ```shell\n",
      "    # Assume you have installed tensorboard\n",
      "    tensorboard --logdir C:\\Users\\dzyyu\\AutoMLTools\\AutoML-Tools\\AutoGluon\\tmp\\8dde5c207412490db4577dc282f2574d-automm_sst\n",
      "    ```\n",
      "\n",
      "- If you are not satisfied with the model, try to increase the training time, \n",
      "adjust the hyperparameters (https://auto.gluon.ai/stable/tutorials/multimodal/advanced_topics/customization.html),\n",
      "or post issues on GitHub: https://github.com/autogluon/autogluon\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<autogluon.multimodal.predictor.MultiModalPredictor at 0x228de2ea250>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from autogluon.multimodal import MultiModalPredictor\n",
    "import uuid\n",
    "\n",
    "#train the model\n",
    "model_path = f\"./tmp/{uuid.uuid4().hex}-automm_sst\"\n",
    "predictor = MultiModalPredictor(label='label', eval_metric='acc', path=model_path)\n",
    "predictor.fit(train_data, time_limit=180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "36aef052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fe35435b8cb44b5ba3c5b757a1c2893",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.582089552238806\n",
      "F1 Score: 0.582089552238806\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Predict the labels for the test data\n",
    "y_pred = predictor.predict(test_data)\n",
    "\n",
    "# Get the true labels from your test_data\n",
    "y_true = test_data['label']  # Adjust 'label' if your column name is different\n",
    "\n",
    "# Calculate accuracy\n",
    "acc = accuracy_score(y_true, y_pred)\n",
    "\n",
    "# Calculate F1 score with your choice of averaging\n",
    "f1 = f1_score(y_true, y_pred, average='micro')  # or 'macro' or 'weighted'\n",
    "\n",
    "print(f\"Accuracy: {acc}\")\n",
    "print(f\"F1 Score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11dcdf9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Description\": The search for the preferred repair facility shall take no longer than 8 seconds.  The preferred repair facility is returned within 8 seconds \"Predicted Sentiment\": PE\n",
      "\"Description\": The product shall be available for distribution as a packaged CD. \"Predicted Sentiment\": F\n"
     ]
    }
   ],
   "source": [
    "#make predictions\n",
    "description1 = \"The search for the preferred repair facility shall take no longer than 8 seconds.  The preferred repair facility is returned within 8 seconds\"\n",
    "description2 = \"The product shall be available for distribution as a packaged CD.\"\n",
    "predictions = predictor.predict({'description': [description1, description2]})\n",
    "print('\"Description\":', description1, '\"Predicted Sentiment\":', predictions[0])\n",
    "print('\"Description\":', description2, '\"Predicted Sentiment\":', predictions[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2eae6a11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">â•­â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•®</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span> <span style=\"color: #800000; text-decoration-color: #800000\">â± </span>1 leaderboard = predictor.leaderboard()                                                        <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">â”‚</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">â•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">AttributeError: </span><span style=\"color: #008000; text-decoration-color: #008000\">'MultiModalPredictor'</span> object has no attribute <span style=\"color: #008000; text-decoration-color: #008000\">'leaderboard'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31mâ•­â”€\u001b[0m\u001b[31mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31mâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\u001b[0m\u001b[31mâ”€â•®\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m1\u001b[0m                                                                                    \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m                                                                                                  \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m \u001b[31mâ± \u001b[0m1 leaderboard = predictor.leaderboard()                                                        \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ”‚\u001b[0m   \u001b[2m2 \u001b[0m                                                                                             \u001b[31mâ”‚\u001b[0m\n",
       "\u001b[31mâ•°â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•¯\u001b[0m\n",
       "\u001b[1;91mAttributeError: \u001b[0m\u001b[32m'MultiModalPredictor'\u001b[0m object has no attribute \u001b[32m'leaderboard'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "leaderboard = predictor.leaderboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20748453",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
